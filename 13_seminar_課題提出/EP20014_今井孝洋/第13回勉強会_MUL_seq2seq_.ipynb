{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2BhrFGqFx_M"
      },
      "source": [
        "# エンコーダ・デコーダによる計算機作成\n",
        "\n",
        "## 目的\n",
        "再帰型ニューラルネットワークの構造を理解する\n",
        "\n",
        "エンコーダ・デコーダモデルの構造を理解する\n",
        "\n",
        "\n",
        "## エンコーダ・デコーダモデル\n",
        "\n",
        "リカレントニューラルネットワークは，系列データ内の関連性を内部状態として保持することができます．\n",
        "この内部状態を利用して，新たな出力ができるようにした構造としてエンコーダ・デコーダがあります．\n",
        "エンコーダ側に系列データを入力して，中間層では系列データ内の関連性を内部状態を形成します．\n",
        "デコーダ側には内部状態を与えることで，内部状態を反映した何かしらの結果を出力します．\n",
        "この応用が，google 翻訳などの機械翻訳です．\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1zFl4Mjo4IRSQWSczJ4PzPkd53YJkb1oM\" width = 100%>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-IW9H7q2fT7"
      },
      "source": [
        "## モジュールのインポートとGPUの確認\n",
        "\n",
        "必要なモジュールをインポートします．\n",
        "そして，GPUが使用可能かどうかを確認します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ksMLJ652faP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14f61fb-e2e9-4bf6-ca4c-15abc66d7aa6"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from time import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# GPUの確認\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use CUDA: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvQCLiV4F1T6"
      },
      "source": [
        "## このノートブックで行う問題設定\n",
        "\n",
        "ここでは**文字として**計算式（足し算）を入力して，**文字として**足し算の結果を出力するネットワークを構築します．\n",
        "\n",
        "具体的には，\"123+39\"のような足し算式の文字列をLSTMEncoderへと入力し，\n",
        "\"162\"のような足し算の結果の文字列をLSTMDecoderから出力させます．\n",
        "\n",
        "このとき，LSTMには数字の文字や\"+\"などの記号の文字をひとつづつ入力・出力させます．\n",
        "\n",
        "## データセットの作成\n",
        "\n",
        "文字とそれに対応したIDを整理した辞書型オブジェクトを作成します．\n",
        "\n",
        "`word2id`では文字をキーとしてIDをデータにもつ辞書を，一方`id2word`ではIDをキーとして文字列をデータに持つ辞書を作成します．\n",
        "\n",
        "作成した辞書を表示します．\n",
        "`word2id`では，0から9の文字は0~9の数字のキーに対応しており，\n",
        "各種記号は次のようなIDに対応しています．\n",
        "* `<pad>`：10\n",
        "* `+`：11\n",
        "* 文字列の終わり`<eos>`：12\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xo3_CHplFN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ce0a97-3136-4290-9ead-6d9a0fcfcb98"
      },
      "source": [
        "word2id = {str(i): i for i in range(10)}\n",
        "word2id.update({\"<pad>\": 10, \"*\": 11, \"<eos>\": 12})\n",
        "id2word = {v: k for k, v in word2id.items()}\n",
        "\n",
        "# 作成した辞書オブジェクトの表示\n",
        "print(word2id)\n",
        "print(id2word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '<pad>': 10, '*': 11, '<eos>': 12}\n",
            "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '<pad>', 11: '*', 12: '<eos>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXKCw7yhlGTI"
      },
      "source": [
        "### データセットクラスの作成\n",
        "\n",
        "次に，データセットを用意します．\n",
        "\n",
        "データは0から9までの数字と加算記号，開始，終了のフラグです．\n",
        "また，３桁の数字の足し算を行うため，各桁の値を１つずつランダムに生成して連結しています．\n",
        "\n",
        "$$x + y = z$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wUc1QN0Fygb"
      },
      "source": [
        "class CalcDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    # 計算式の文字列をIDの配列に変換するための関数\n",
        "    def transform(self, string, seq_len=7):\n",
        "        tmp = []\n",
        "        for i, c in enumerate(string):\n",
        "            try:\n",
        "                tmp.append(word2id[c])\n",
        "            except:\n",
        "                tmp += [word2id[\"<pad>\"]] * (seq_len - i)\n",
        "                break\n",
        "        return tmp\n",
        "\n",
        "    def __init__(self, data_num, train=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.data_num = data_num   # 準備するデータ（計算式）の数\n",
        "        self.train = train         # 学習，テストのどちらか\n",
        "        self.data = []             # 入力データ（足し算式の文字列）を格納するリスト\n",
        "        self.label = []            # 正解（足し算結果の文字列）を格納するリスト\n",
        "\n",
        "        # data_numの数だけforループを回して足し算式データをランダムに作成\n",
        "        for _ in range(data_num):\n",
        "            # 入力データの作成 (x + y) \n",
        "            x = int(\"\".join([random.choice(list(\"0123456789\")) for _ in range(random.randint(1, 3))] )) # 0 ~ 999の適当な数字（整数）を生成\n",
        "            y = int(\"\".join([random.choice(list(\"0123456789\")) for _ in range(random.randint(1, 3))] )) # 0 ~ 999の適当な数字（整数）を生成\n",
        "            left = (\"{:*<7s}\".format(str(x) + \"*\" + str(y))).replace(\"*\", \"<pad>\")  # x+yの計算式の文字列を作成\n",
        "            self.data.append(self.transform(left))  # 作成した計算文字列をID配列に変換してリストに格納\n",
        "\n",
        "            z = x * y  # 足し算の答えを計算\n",
        "            right = (\"{:*<12s}\".format(str(z))).replace(\"*\", \"<pad>\")  # 答えの数値を文字列に変換\n",
        "            right = self.transform(right, seq_len=9)                  # 文字列 --> IDの配列に変換\n",
        "            right = [12] + right         # ['EOS', '答えの数字ID', ...]となるように'EOS'を連結（計算上の仕様）\n",
        "            right[right.index(10)] = 12  # ['EOS', '答えの数字ID', ..., 'EOS', 'PAD', 'PAD']となるようにIDを変更  12 = EOS\n",
        "            self.label.append(right)     # 作成した答えのID配列を保存\n",
        "        \n",
        "        # リスト --> numpy array形式に変換\n",
        "        self.data = np.asarray(self.data)\n",
        "        self.label = np.asarray(self.label)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        d = self.data[item]\n",
        "        l = self.label[item]\n",
        "        return d, l\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 入力データの作成 (x + y) \n",
        "x = int(\"\".join([random.choice(list(\"0123456789\")) for _ in range(random.randint(1, 3))] )) # 0 ~ 999の適当な数字（整数）を生成\n",
        "y = int(\"\".join([random.choice(list(\"0123456789\")) for _ in range(random.randint(1, 3))] )) # 0 ~ 999の適当な数字（整数）を生成\n",
        "left = (\"{:*<7s}\".format(str(x) + \"*\" + str(y))).replace(\"*\", \"<pad>\")  # x+yの計算式の文字列を作成\n",
        "print(\"x:\",x)\n",
        "print(\"y:\",y)\n",
        "print(\"left:\",left)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKqd0TSsLXrG",
        "outputId": "3707a41d-60a4-4283-b078-2a58aa428560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: 33\n",
            "y: 24\n",
            "left: 33<pad>24<pad><pad>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = x * y  # 足し算の答えを計算\n",
        "right = (\"{:*<12s}\".format(str(z))).replace(\"*\", \"<pad>\")  # 答えの数値を文字列に変換\n",
        "print(\"z:\",z)\n",
        "print(\"right:\",right)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk-Gxf3dLgSc",
        "outputId": "098257f5-b412-43c8-d5ce-0b2bfbe81d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z: 792\n",
            "right: 792<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvI-V5Dndj3A"
      },
      "source": [
        "### 作成したデータの確認\n",
        "\n",
        "作成した`CalcDataset`のデータを確認します．\n",
        "\n",
        "適当なデータセットとして`tmp_dataset`を作成します．今回はデータの確認を行うだけのため，データ数（`data_num`）は5と小さい数に指定します．\n",
        "\n",
        "そして，作成したデータセット内のデータをひとつづつfor文で読み出して，データを確認します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJzPv5j7zWD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e9fc0a-fbfe-42c4-91eb-1ed722c22b95"
      },
      "source": [
        "tmp_dataset = CalcDataset(data_num=5)\n",
        "\n",
        "for i in range(len(tmp_dataset)):\n",
        "    print(tmp_dataset[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([ 0, 10, 10, 10, 10, 10, 10]), array([12,  0, 12, 10, 10, 10, 10, 10, 10, 10]))\n",
            "(array([ 5,  2, 10, 10, 10, 10, 10]), array([12,  2,  6,  0, 12, 10, 10, 10, 10, 10]))\n",
            "(array([ 9,  0, 10, 10, 10, 10, 10]), array([12,  5,  4,  0, 12, 10, 10, 10, 10, 10]))\n",
            "(array([ 6,  0, 10, 10, 10, 10, 10]), array([12,  3,  7,  2,  0, 12, 10, 10, 10, 10]))\n",
            "(array([ 8,  3, 10, 10, 10, 10, 10]), array([12,  1,  9,  9,  2, 12, 10, 10, 10, 10]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTHnQ96hF7cd"
      },
      "source": [
        "## ネットワークモデル（計算機）の定義\n",
        "ここでは，エンコーダ・デコーダ構造で計算機（足し算）を作ってみます．\n",
        "このエンコーダ・デコーダ構造のことをSequence-to-Sequence (Seq2Seq) と呼びます．\n",
        "\n",
        "エンコーダとデコーダの2種類のネットワークを用意します．\n",
        "エンコーダは，ワードエンベディング (word embedding) という入力されたIDを特徴表現に変換する層とLSTM層から構成されています．\n",
        "デコーダも同様の構造です．エンコーダ側の中間層の値がstateとして出力され，デコーダ側の中間層に入力されます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0IE4XYHF690"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    # vocab_size: 扱うIDの数, embedding_dim: embedding層の特徴次元数, hidden_dim: LSTMの隠れ層サイズ\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size=100):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # padding_idx: padのID (10) を指定（このIDが入力された場合は出力が全て0になる）\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2id[\"<pad>\"])\n",
        "        # batch_first: 入力データの1次元目がミニバッチかどうか（Trueの場合...[mini batch, seqence, feature] となる）\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)                                                                ######\n",
        "\n",
        "    def forward(self, indices):\n",
        "        embedding = self.word_embeddings(indices)\n",
        "        # 配列サイズの確認と適宜サイズ変更（embeddingのサイズが2次元配列の場合には1次元追加して[mini batch, seqence, feature]の形にする）\n",
        "        if embedding.dim() == 2:\n",
        "            embedding = torch.unsqueeze(embedding, 1)\n",
        "        h = torch.zeros(1, self.batch_size, self.hidden_dim, device=device)\n",
        "        c = torch.zeros(1, self.batch_size, self.hidden_dim, device=device)\n",
        "        # データをLSTMへ一度に入力し，最後のデータを入れ終わった後の隠れ状態とセル状態（state）を取得\n",
        "        _, state = self.lstm(embedding, (h, c))\n",
        "        #_, state = self.lstm(embedding, h)\n",
        "        return state\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size=100):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2id[\"<pad>\"])\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.output = nn.Linear(hidden_dim, vocab_size)  # 各IDのスコアが出力されるようにIDの数と同一の出力サイズにする\n",
        "\n",
        "    def forward(self, index, state):\n",
        "        embedding = self.word_embeddings(index)\n",
        "        if embedding.dim() == 2:\n",
        "            embedding = torch.unsqueeze(embedding, 1)\n",
        "        lstm_out, state = self.lstm(embedding, state)\n",
        "        output = self.output(lstm_out)  # lstm_outを全結合層（出力層）へ入力して計算結果の文字（各ID）のスコアを取得\n",
        "        return output, state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-cRJNLIBKOs"
      },
      "source": [
        "## ネットワークモデルの作成\n",
        "\n",
        "上で定義したエンコーダとデコーダを作成します．\n",
        "エンコーダとデコーダは別々のネットワークとして用意し，それぞれの最適化にはAdamを利用します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpsqOdLnBKUf"
      },
      "source": [
        "embedding_dim = 16\n",
        "hidden_dim = 128\n",
        "vocab_size = len(word2id)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "encoder = Encoder(vocab_size, embedding_dim, hidden_dim, batch_size=100).to(device)\n",
        "decoder = Decoder(vocab_size, embedding_dim, hidden_dim, batch_size=100).to(device)\n",
        "\n",
        "# 正解ラベルにPAD (ID=10) が入力された場合は誤差を計算しない\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=word2id[\"<pad>\"])\n",
        "\n",
        "# 最適化手法の設定\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jPYDEx8F-d6"
      },
      "source": [
        "###学習\n",
        "学習を行います．学習データを2万サンプル生成して，データローダに与えます．\n",
        "学習は200エポック行います．エンコーダの入力は数字または開始・終了・加算記号です．\n",
        "デコーダの入力は計算結果です．\n",
        "具体的には，54+37 を行う時，\n",
        "エンコーダには，まず開始記号を最初に入力し，次に，5, 4, +, 3, 7 を入力します．そして，最後に終了記号を入力します．その時の中間層の情報をhidden_stateとしてエンコーダから受け取ります．\n",
        "デコーダは，開始記号と中間情報(hidden_state)を最初に入力します，そして，計算結果の9, 1 を入力し，最後に終了記号を入力します．\n",
        "この時，デコーダは各数字（または記号）の確率をdecoder_outputとして出力します．\n",
        "decoder_outputは，[バッチサイズ, 1, 各クラス確率]の３次元なので，squeezeによって，[バッチサイズ,  各クラス確率] に次元削減します．\n",
        "そして，クロスエントロピー誤差関数によって，ロスを求めます．\n",
        "これを正解の長さ(=5)分繰り返し行い，ロスを累積します．\n",
        "その後，誤差逆伝播，デコーダ，エンコーダの更新を行います．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6oQRPeTF-Bj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "f7e29027-a4e9-4f60-df0d-a9942cbfdd6b"
      },
      "source": [
        "batch_size=100\n",
        "epoch_num = 50\n",
        "\n",
        "train_data = CalcDataset(data_num = 20000)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    for data, label in train_loader:\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        encoder_hidden = encoder(data)\n",
        "        source = label[:, :-1]  # 学習時にデコーダに入力するデータを抽出\n",
        "        target = label[:, 1:]   # 正解ラベルを抽出\n",
        "        decoder_hidden = encoder_hidden  # エンコーダの隠れ・セル状態をデコーダへ渡すためにコピー\n",
        "\n",
        "        loss = 0\n",
        "        for i in range(source.size(1)):\n",
        "            decoder_output, decoder_hidden = decoder(source[:, i], decoder_hidden)\n",
        "            decoder_output = torch.squeeze(decoder_output)\n",
        "            loss += criterion(decoder_output, target[:, i])\n",
        "\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "    elapsed_time = time() - start\n",
        "    if epoch % 10 == 0:\n",
        "        print(\"epoch: {}, mean loss: {}, elapsed_time: {}\".format(epoch, loss.item(), elapsed_time))\n",
        "\n",
        "# 学習が一通り終了した時点で，ネットワークモデルのパラメータを保存\n",
        "model_name = \"seq2seq_calculator_v{}.pt\".format(epoch)\n",
        "torch.save({\n",
        "    'encoder_model': encoder.state_dict(),\n",
        "    'decoder_model': decoder.state_dict(),\n",
        "}, model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, mean loss: nan, elapsed_time: 20.551557779312134\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-019d8abdf67e>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-8368668ccb53>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, index, state)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# lstm_outを全結合層（出力層）へ入力して計算結果の文字（各ID）のスコアを取得\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    813\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    814\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVUbOtyfGLwA"
      },
      "source": [
        "## 評価\n",
        "\n",
        "次に，学習したモデルを評価をします．\n",
        "\n",
        "テストデータを50サンプル生成して，データローダに与えます．\n",
        "\n",
        "ここで，学習時はエンコーダとデコーダのバッチサイズを100としていました．\n",
        "テスト時は１つずつ行いたいので，エンコーダとデコーダを新たに生成し，学習したパラメータをロードします．\n",
        "\n",
        "エンコーダ側に計算したい数字（または記号）を入力して中間情報stateを得ます．\n",
        "デコーダ側に，中間情報stateと開始記号<eos>を入力します．\n",
        "デコーダ側の出力は数字または記号(token)と中間情報です．\n",
        "これらを繰り返しデコーダに入力します．<eos>が出力されたら繰り返しは終了です．\n",
        "\n",
        "出力されたtokenを追加したリストrightを計算結果とします．\n",
        "計算する式(left)を作成した後，evalでその計算結果が正しいかどうかを判定します．\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPUが使用できず，学習ができなかった場合\n",
        "\n",
        "学習済みモデルを用意していますので，下記のコマンドを実行してファイルをダウンロードしてください．"
      ],
      "metadata": {
        "id": "L8HmISAuuku_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -qq http://www.mprg.cs.chubu.ac.jp/~hirakawa/share/tutorial_data/seq2seq_calculator_v200.pt.zip\n",
        "!unzip seq2seq_calculator_v200.pt.zip"
      ],
      "metadata": {
        "id": "9aKoUyD5ukl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "319d7acf-b89a-4b9e-ffb9-be5471d87ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  seq2seq_calculator_v200.pt.zip\n",
            "replace seq2seq_calculator_v200.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGdS8DWwGC_D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "7a4ce2a6-d631-4e18-a1a0-4706a5447d24"
      },
      "source": [
        "batch_size = 1\n",
        "test_data = CalcDataset(data_num = 50)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "encoder = Encoder(vocab_size, embedding_dim, hidden_dim, batch_size=1).to(device)\n",
        "decoder = Decoder(vocab_size, embedding_dim, hidden_dim, batch_size=1).to(device)\n",
        "\n",
        "model_name = \"seq2seq_calculator_v{}.pt\".format(epoch)\n",
        "checkpoint = torch.load(model_name)\n",
        "encoder.load_state_dict(checkpoint[\"encoder_model\"])\n",
        "decoder.load_state_dict(checkpoint[\"decoder_model\"])\n",
        "\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "accuracy = 0\n",
        "        \n",
        "# 評価の実行   \n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "\n",
        "        # encoderの計算\n",
        "        state = encoder(data)\n",
        "\n",
        "        # decoderの計算\n",
        "        right = []\n",
        "        token = \"<eos>\"\n",
        "        for _ in range(7):\n",
        "            index = word2id[token]  # decoderに入力するIDを決定（最初はEOS, 次から前の時刻のdecoderの出力）\n",
        "            input_tensor = torch.tensor([index], device=device)  # IDをtorchの配列形式に変換\n",
        "            output, state = decoder(input_tensor, state)         # IDを入力\n",
        "            prob = F.softmax(torch.squeeze(output), dim=0)       # softmaxを計算\n",
        "            index = torch.argmax(prob.cpu().detach()).item()     # 出力の中で最もスコアの高いIDを決定\n",
        "            token = id2word[index]                               # そのIDを文字に変換\n",
        "            if token == \"<eos>\":  # 予測結果がEOSなら終了\n",
        "                break\n",
        "            right.append(token)                                  # 文字に変換した予測結果をリストに格納\n",
        "        right = \"\".join(right)\n",
        "        \n",
        "        # 計算式（左辺）のID配列 --> 文字列に変換（表示用）\n",
        "        x = list(data[0].to('cpu').detach().numpy())\n",
        "        try:\n",
        "            padded_idx_x = x.index(word2id[\"<pad>\"])\n",
        "        except ValueError:\n",
        "            padded_idx_x = len(x)\n",
        "        left = \"\".join(map(lambda c: str(id2word[c]), x[:padded_idx_x]))\n",
        "\n",
        "        # 正解判定\n",
        "        try:\n",
        "          right_int = int(right)          # 予測結果の文字列を数値に変換\n",
        "          flag = eval(left) == right_int  # 正しければTrueを保存\n",
        "        except:\n",
        "          flag = False\n",
        "\n",
        "        print(\"{:>7s} = {:>4s}\".format(left, right), flag)  # 計算結果の表示\n",
        "\n",
        "        if flag:\n",
        "            accuracy += 1   # 正解した場合はカウントする\n",
        "\n",
        "print(\"Accuracy: {:.2f}\".format(accuracy / len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-e5caaff44a17>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"seq2seq_calculator_v{}.pt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"decoder_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seq2seq_calculator_v13.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVqKQdWxGOg5"
      },
      "source": [
        "## 課題\n",
        "\n",
        "### 1. 他のリカレントニューラルネットワークを使って精度比較をしてみましょう．\n",
        "\n",
        "**ヒント**\n",
        "\n",
        "その他のネットワークとしては`nn.RNN`や`nn.GRU`があります．\n",
        "\n",
        "また，RNNやGRUにはセル状態がないため，変数`c`を使用しないように注意\n",
        "```\n",
        "self.lstm(embedding, (h, c)) --> self.lstm(embedding, h)\n",
        "```\n",
        "\n",
        "\n",
        "### 2. 足し算だけでなく，色々な四則演算を実装しましょう．\n",
        "**こちらは時間があれば取り組んでみましょう**"
      ]
    }
  ]
}